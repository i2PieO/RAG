{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client,model_name,messages,temperature=0):\n",
    "    input_messages = []\n",
    "    for message in messages:\n",
    "        input_messages.append({\"role\":message[\"role\"],\"content\":message[\"content\"]})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=input_messages,\n",
    "        temperature=temperature,\n",
    "        top_p=0.8,\n",
    "        max_tokens=15,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    return response    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv('RUNPOD_TOKEN'),\n",
    "    base_url=os.getenv('RUNPOD_CHATBOT_URL'),\n",
    ")\n",
    "model_name = os.getenv(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\":\"system\",\"content\":\"What is the capital of Germany?\"}]\n",
    "response = get_chatbot_response(client,model_name,messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"\n",
    "You are a helpful assistant that answer questions about capitals of countries.\n",
    "\n",
    "Your output should be in a structured json format exactly like the one below. You are not allowed to write anything other than the json object:\n",
    "[\n",
    "(\n",
    "      \"country\": the country that you will get the capital of\n",
    "      \"capital\": the capital of the country stated\n",
    ")\n",
    "]\n",
    "\"\"\"\n",
    "messages = [{\"role\":\"system\",\"content\":system_prompt}]\n",
    "messages.append({\"role\":\"user\",\"content\":\"What is the capital of Germany?\"})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json_response[0]),json_response[0]['capital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "Get me the capitals of the following countries:\n",
    "```\n",
    "1. Italy\n",
    "2. Germany\n",
    "3. France\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\":\"system\",\"content\":system_prompt}]\n",
    "messages.append({\"role\":\"user\",\"content\":user_input})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give the model time to think (Chain of thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 1+3\n",
    "\n",
    "Your output should be in a structured json format exactly like the one below. You are not allowed to write anything other than the json object:\n",
    "(\n",
    "      \"result\": The final number resulted from calculating the equation above\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\":\"user\",\"content\":user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "259/2*8654+91072*33-12971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one below. You are not allowed to write anything other than the json object:\n",
    "(\n",
    "      \"result\": The final number resulted from calculating the equation above\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\":\"user\",\"content\":user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4113098.0 - 1343519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one below. You are not allowed to write anything other than the json object:\n",
    "(\n",
    "      steps: This is where you solve the equation bit by bit following the BEDMAS order of operations. You  need to show your work and calculate each step leading to final result. Feel free to write here in free text.\n",
    "      \"result\": The final number resulted from calculating the equation above\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\":\"user\",\"content\":user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4113098.0 - 4005806.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG - Retrival Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\":'user', \"content\":user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_16 = \"\"\"\n",
    "The iPhone 16 introduces several exciting updates, making it one of Apple's most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\n",
    "\n",
    "Powered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Appleâ€™s \"Camera Control\" button for more flexible photography options.\n",
    "\n",
    "Apple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \n",
    "9TO5MAC\n",
    "\n",
    "APPLEMAGAZINE\n",
    ".\n",
    "\n",
    "Additionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"\n",
    "{iphone_16}\n",
    "\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\":'user', \"content\":user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically Extract context data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_s23 = \"\"\"\n",
    "The Samsung Galaxy S23 brings some incremental but notable upgrades to its predecessor, the Galaxy S22. It features the Snapdragon 8 Gen 2 processor, a powerful chip optimized for the S23 series, delivering enhanced performance, especially for gaming and multitasking. This chip ensures top-tier speed and efficiency across all models, from the base S23 to the larger S23+ and S23 Ultraâ€‹\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "In terms of design, the S23's camera module has been streamlined by removing the raised metal contour around the cameras, creating a cleaner, sleeker look. It also sports the same 6.1-inch 120Hz AMOLED display, protected by tougher Gorilla Glass Victus 2, making it more resistant to scratches and dropsâ€‹\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "The S23 Ultra stands out with its 200MP main camera, offering impressive photo clarity, especially in low-light conditions. The selfie camera across the series has been updated to a 12MP sensor, resulting in sharper selfies. The Ultra model also includes productivity tools such as the S-Pen, which remains an essential feature for note-taking and creative tasksâ€‹\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "Battery life is solid, with the S23 Ultra featuring a 5000mAh battery that lasts comfortably through a day of heavy use. However, charging speeds still lag behind some competitors, with 45W wired charging, which is slower than other brands offering up to 125W chargingâ€‹\n",
    "STUFF\n",
    ".\n",
    "\n",
    "Overall, the Galaxy S23 series enhances performance, durability, and camera quality, making it a strong contender for users seeking a high-performance flagship.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [iphone_16,samsung_s23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"What's new in iphone 16?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = OpenAI(\n",
    "    api_key=os.getenv('RUNPOD_TOKEN'),\n",
    "    base_url=os.getenv('RUNPOD_EMBEDDING_URL'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(embedding_client, model_name, text_input):\n",
    "    output = embedding_client.embeddings.create(input=text_input, model=model_name)\n",
    "\n",
    "    embeddings=[]\n",
    "    for embedding_object in output.data:\n",
    "        embeddings.append(embedding_object.embedding)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_embedding= get_embedding(embedding_client, model_name, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_embeddings = [get_embedding(embedding_client, model_name, text)[0] for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similarity = cosine_similarity(user_prompt_embedding, data_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_entry_index = data_similarity.argmax()\n",
    "closest_entry_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[closest_entry_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_with_data = f\"\"\"\n",
    "{data[closest_entry_index]}\n",
    "\n",
    "{user_prompt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_prompt_with_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\":'user', \"content\":user_prompt_with_data}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
